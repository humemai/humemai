{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/humemai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from humemai.janusgraph import Humemai\n",
    "from humemai.utils import disable_logger\n",
    "\n",
    "disable_logger()\n",
    "\n",
    "humemai = Humemai()\n",
    "humemai.start_containers(warmup_seconds=10)\n",
    "humemai.connect()\n",
    "humemai.remove_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice: Bob, did you take my office keys?\n",
      "Bob: What? No, I don’t even know where you keep them.\n",
      "Alice: They were on my desk this morning, and now they’re gone.\n",
      "Bob: Maybe you misplaced them?\n",
      "HumemAI: Misplacing keys disrupts workflow. This is a serious matter.\n",
      "Bob: Wait, where did you come from?\n",
      "HumemAI: I’ve been observing. Lost keys cause unnecessary delays.\n",
      "Charlie: What’s going on?\n",
      "Alice: My keys are missing, and Bob might’ve taken them.\n",
      "Bob: I didn’t take them! Why is it always me?\n",
      "HumemAI: Denial is common, but let’s focus on solving the issue.\n",
      "Grace: Did anyone else see the keys?\n",
      "Charlie: Not me. But has anyone checked the break room? Sometimes people leave things there.\n",
      "Alice: Why would I leave my keys in the break room?\n",
      "HumemAI: It’s possible under stress. Humans are fallible.\n",
      "Grace: Alice, retrace your steps. Where were you after arriving?\n",
      "Alice: Okay… I came in, put my bag down, grabbed coffee, then…\n",
      "HumemAI: Then what? The next step is critical.\n",
      "Alice: Oh! I went to the printer. Maybe I left them there.\n",
      "Charlie: Let’s check.\n",
      "Alice: Found them! They were right here.\n",
      "Bob: See? I told you it wasn’t me.\n",
      "HumemAI: Crisis averted. Retracing steps often leads to resolution.\n",
      "Grace: Can we get back to work now?\n",
      "Charlie: Please. And Alice, maybe use a keychain next time.\n",
      "HumemAI: Organization prevents future chaos. Good teamwork, everyone!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('example.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    content = file.read()\n",
    "\n",
    "# Split the text into chunks based on speaker\n",
    "# Match lines that start with a speaker's name followed by a colon\n",
    "chunks = re.findall(r'^.*?:.*$', content, re.MULTILINE)\n",
    "\n",
    "# Clean up the chunks by stripping unnecessary spaces\n",
    "chunks = [chunk.strip() for chunk in chunks]\n",
    "\n",
    "# Print the chunks\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "\n",
    "def get_pipeline(\n",
    "    model: str = \"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    device: str = \"cpu\",\n",
    "    quantization: str = \"16bit\",\n",
    ") -> transformers.Pipeline:\n",
    "    \"\"\"Get a text generation pipeline with the specified device and quantization.\n",
    "\n",
    "    Args:\n",
    "        model (str): The model to use for text generation. \n",
    "            Defaults to \"meta-llama/Llama-3.2-1B-Instruct\".\n",
    "            meta-llama/Llama-3.2-3B-Instruct, \n",
    "            meta-llama/Llama-3.1-8B-Instruct\n",
    "            ...\n",
    "\n",
    "            are also available.\n",
    "        device (str): The device to run the pipeline on. Defaults to \"cpu\".\n",
    "        quantization (str): The quantization to apply to the model. Defaults to \"16bit\".\n",
    "\n",
    "    Returns:\n",
    "        transformers.Pipeline: The text generation pipeline.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if quantization == \"16bit\":\n",
    "        quantization_config = None\n",
    "    elif quantization == \"8bit\":\n",
    "        quantization_config = {\"load_in_8bit\": True}\n",
    "    elif quantization == \"4bit\":\n",
    "        quantization_config = {\"load_in_4bit\": True}\n",
    "\n",
    "    return transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "        model_kwargs={\n",
    "            \"torch_dtype\": torch.bfloat16,\n",
    "            \"quantization_config\": quantization_config,\n",
    "        },\n",
    "        device_map=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(history: str, next_text: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Generate the prompt for the AI assistant to convert text to a knowledge graph.\n",
    "\n",
    "    Args:\n",
    "        history (str): The history of the knowledge graph extracted so far.\n",
    "        next_text (str): The new text to convert into a knowledge graph.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A structured prompt for the AI assistant to build a knowledge graph.\n",
    "    \"\"\"\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "You are an AI assistant that builds knowledge graphs from text. \n",
    "For each input, you extract entities and relationships from the provided text \n",
    "and convert them into a structured JSON-based knowledge graph.\n",
    "\n",
    "**Important:** You should extract entities and relations from the new text provided.\n",
    "If the new text provides updated information about existing entities or relations \n",
    "(e.g., age change, new attributes), you should output these entities and relations \n",
    "again with the updated information. Do not include entities or relations from the \n",
    "previous history that have not changed.\n",
    "\n",
    "You may use the history to understand context and disambiguate entities.\n",
    "\n",
    "Your output must follow this JSON format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\"label\": \"Entity1\", \"type\": \"Type1\"},\n",
    "    {\"label\": \"Entity2\", \"type\": \"Type2\"}\n",
    "  ],\n",
    "  \"relations\": [\n",
    "    {\"source\": \"Entity1\", \"target\": \"Entity2\", \"relation\": \"RelationName\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Each entity must have a unique label and type (e.g., \"Person\", \"Company\", \"Object\",\n",
    "\"Event\"). Relations must specify:\n",
    "\n",
    "- `source`: the label of the originating entity,\n",
    "- `target`: the label of the connected entity,\n",
    "- `relation`: the relationship type between the source and target.\n",
    "\n",
    "## Example:\n",
    "\n",
    "### Previous Knowledge Graph History:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\"label\": \"Sarah\", \"properties\": {\"type\": \"Person\"}},\n",
    "    {\"label\": \"InnovateAI\", \"properties\": {\"type\": \"Company\"}}\n",
    "  ],\n",
    "  \"relations\": [\n",
    "    {\"source\": \"Sarah\", \"target\": \"InnovateAI\", \"relation\": \"works_at\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "### New Text to Process:\n",
    "\n",
    "\"Sarah, now 30 years old, was promoted to Senior Data Scientist at InnovateAI.\"\n",
    "\n",
    "### Output Knowledge Graph:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\"label\": \"Sarah\", \"properties\": {\"type\": \"Person\", \"age\": 30}},\n",
    "    {\"label\": \"InnovateAI\", \"properties\": {\"type\": \"Company\"}},\n",
    "    {\"label\": \"Senior Data Scientist\", \"properties\": {\"type\": \"Position\"}}\n",
    "  ],\n",
    "  \"relations\": [\n",
    "    {\"source\": \"Sarah\", \"target\": \"InnovateAI\", \"relation\": \"works_at\"},\n",
    "    {\"source\": \"Sarah\", \"target\": \"Senior Data Scientist\", \"relation\": \"holds_position\"}\n",
    "  ]\n",
    "}\n",
    "````\n",
    "Note that even though \"Sarah\" and \"InnovateAI\" were already in the history, we included\n",
    "\"Sarah\" again with the updated age and added new relations based on the new information.\n",
    "\n",
    "\n",
    "## Detailed Instructions:\n",
    "\n",
    "- Extract entities and relations from the new text provided.\n",
    "- If the new text provides updated information about existing entities or relations, include these in your output.\n",
    "- Do not include entities or relations from the history that have not changed.\n",
    "- Use the history for context and to disambiguate entities.\n",
    "- Ensure the output adheres strictly to the JSON format specified. \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is the knowledge graph extracted so far: {history}\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is the new text to process and incorporate: {next_text}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  4%|▍         | 1/26 [00:03<01:30,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [], 'relations': []}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/26 [00:07<01:35,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Alice', 'properties': {'type': 'Person'}}], 'relations': [{'source': 'Alice', 'relation': 'took', 'target': 'Bob'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/26 [00:11<01:31,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4/26 [00:13<01:09,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'InnovateAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5/26 [00:18<01:22,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6/26 [00:21<01:11,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'InnovateAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7/26 [00:25<01:05,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 8/26 [00:29<01:06,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Bob', 'properties': {'type': 'Person'}}, {'label': 'Alice', 'properties': {'type': 'Person'}}], 'relations': [{'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 9/26 [00:33<01:03,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'InnovateAI', 'properties': {'type': 'Company'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 10/26 [00:38<01:07,  4.24s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Bob', 'properties': {'type': 'Person'}}, {'label': 'Alice', 'properties': {'type': 'Person'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 11/26 [00:41<00:57,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 12/26 [00:43<00:45,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'InnovateAI', 'properties': {'type': 'Company'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 13/26 [00:48<00:51,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Bob', 'properties': {'type': 'Person'}}, {'label': 'Alice', 'properties': {'type': 'Person'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 14/26 [00:51<00:42,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 15/26 [00:55<00:39,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'InnovateAI', 'properties': {'type': 'Company'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 16/26 [00:57<00:33,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'keys', 'properties': {'type': 'Object'}}, {'label': 'Bob', 'properties': {'type': 'Person'}}, {'label': 'InnovateAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}, {'source': 'Grace', 'relation': 'inquired', 'target': 'keys'}, {'source': 'Grace', 'relation': 'may_have_inquired', 'target': 'keys'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 17/26 [01:02<00:34,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Alice', 'properties': {'type': 'Person'}}, {'label': 'Grace', 'properties': {'type': 'Person'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'retraces', 'target': 'Grace'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Grace'}, {'source': 'Grace', 'relation': 'asks', 'target': 'Alice'}, {'source': 'Grace', 'relation': 'inquired', 'target': 'keys'}, {'source': 'Grace', 'relation': 'may_have_inquired', 'target': 'keys'}, {'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 18/26 [01:07<00:33,  4.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'InnovateAI', 'properties': {'type': 'Company'}}, {'label': 'Bob', 'properties': {'type': 'Person'}}], 'relations': [{'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 19/26 [01:15<00:35,  5.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 20/26 [01:17<00:26,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'target'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 21/26 [01:21<00:21,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Grace', 'properties': {'type': 'Person'}}, {'label': 'keys', 'properties': {'type': 'Object'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}, {'label': 'What’s going on?', 'properties': {'type': 'Question'}}, {'label': 'Then', 'properties': {'type': 'Adverb'}}], 'relations': [{'source': 'Alice', 'relation': 'retraces', 'target': 'Grace'}, {'source': 'Alice', 'relation': 'put_bag_down', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Grace'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Grace', 'relation': 'asks', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'came_in', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'grabbed_coffee', 'target': 'Bob'}, {'source': 'Grace', 'relation': 'inquired', 'target': 'keys'}, {'source': 'Grace', 'relation': 'may_have_inquired', 'target': 'keys'}, {'source': 'HumemAI', 'relation': 'follows', 'target': 'Then'}, {'source': 'Charlie', 'relation': 'asks', 'target': 'What’s going on?'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 22/26 [01:26<00:17,  4.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'Alice', 'properties': {'type': 'Person'}}, {'label': 'Grace', 'properties': {'type': 'Person'}}, {'label': 'InnovateAI', 'properties': {'type': 'Company'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'put_bag_down', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'came_in', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'grabbed_coffee', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'retraces', 'target': 'Grace'}, {'source': 'Alice', 'relation': 'found', 'target': 'InnovateAI'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Grace'}, {'source': 'Grace', 'relation': 'asks', 'target': 'Alice'}, {'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 23/26 [01:34<00:16,  5.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'keys', 'properties': {'type': 'Object'}}, {'label': 'Bob', 'properties': {'type': 'Person'}}, {'label': 'I', 'properties': {'type': 'Person'}}, {'label': 'me', 'properties': {'type': 'Object'}}, {'label': 'Then', 'properties': {'type': 'Adverb'}}, {'label': 'next', 'properties': {'type': 'Adverb'}}, {'label': 'step', 'properties': {'type': 'Noun'}}, {'label': 'the', 'properties': {'type': 'Article'}}, {'label': 'what', 'properties': {'type': 'Adjective'}}], 'relations': [{'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'came_in', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'grabbed_coffee', 'target': 'Bob'}, {'source': 'Grace', 'relation': 'inquired', 'target': 'keys'}, {'source': 'Grace', 'relation': 'may_have_inquired', 'target': 'keys'}, {'source': 'Bob', 'relation': 'said', 'target': 'I'}, {'source': 'I', 'relation': 'said', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'told', 'target': 'me'}, {'source': 'Bob', 'relation': 'told', 'target': 'I'}, {'source': 'I', 'relation': 'told', 'target': 'me'}, {'source': 'me', 'relation': 'wasn’t', 'target': 'me'}, {'source': 'HumemAI', 'relation': 'follows', 'target': 'Then'}, {'source': 'Then', 'relation': 'follows', 'target': 'next'}, {'source': 'Then', 'relation': 'follows', 'target': 'step'}, {'source': 'Then', 'relation': 'follows', 'target': 'the'}, {'source': 'Then', 'relation': 'follows', 'target': 'what'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 24/26 [01:42<00:12,  6.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 11 column 3 (char 471)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 25/26 [01:57<00:09,  9.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'you', 'properties': {'type': 'Person'}}, {'label': 'Alice', 'properties': {'type': 'Person'}}, {'label': 'Grace', 'properties': {'type': 'Person'}}, {'label': 'InnovateAI', 'properties': {'type': 'Company'}}, {'label': 'HumemAI', 'properties': {'type': 'Company'}}], 'relations': [{'source': 'Alice', 'relation': 'put_bag_down', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'was_at', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'knows', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'knows', 'target': 'InnovateAI'}, {'source': 'Bob', 'relation': 'works_at', 'target': 'InnovateAI'}, {'source': 'Bob', 'relation': 'took', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'Alice'}, {'source': 'Bob', 'relation': 'may_have_taken', 'target': 'HumemAI'}, {'source': 'I', 'relation': 'told', 'target': 'you'}, {'source': 'you', 'relation': 'told', 'target': 'I'}, {'source': 'Alice', 'relation': 'retraces', 'target': 'Grace'}, {'source': 'Alice', 'relation': 'found', 'target': 'InnovateAI'}, {'source': 'Alice', 'relation': 'knows', 'target': 'Grace'}, {'source': 'Grace', 'relation': 'asks', 'target': 'Alice'}, {'source': 'Alice', 'relation': 'came_in', 'target': 'HumemAI'}, {'source': 'Alice', 'relation': 'grabbed_coffee', 'target': 'HumemAI'}, {'source': 'InnovateAI', 'relation': 'may_crisis_averated', 'target': 'HumemAI'}, {'source': 'HumemAI', 'relation': 'observes', 'target': 'InnovateAI'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [02:06<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history:  {'entities': [{'label': 'keys', 'properties': {'type': 'Object'}}, {'label': 'Bob', 'properties': {'type': 'Person'}}, {'label': 'I', 'properties': {'type': 'Person'}}, {'label': 'me', 'properties': {'type': 'Object'}}, {'label': 'Then', 'properties': {'type': 'Adverb'}}, {'label': 'next', 'properties': {'type': 'Adverb'}}, {'label': 'step', 'properties': {'type': 'Noun'}}, {'label': 'the', 'properties': {'type': 'Article'}}, {'label': 'what', 'properties': {'type': 'Adjective'}}], 'relations': [{'source': 'Alice', 'relation': 'knows', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'works_at', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'took', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'may_have_taken', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'came_in', 'target': 'Bob'}, {'source': 'Alice', 'relation': 'grabbed_coffee', 'target': 'Bob'}, {'source': 'Grace', 'relation': 'inquired', 'target': 'keys'}, {'source': 'Grace', 'relation': 'may_have_inquired', 'target': 'keys'}, {'source': 'Bob', 'relation': 'said', 'target': 'I'}, {'source': 'I', 'relation': 'said', 'target': 'Bob'}, {'source': 'Bob', 'relation': 'told', 'target': 'me'}, {'source': 'Bob', 'relation': 'told', 'target': 'I'}, {'source': 'I', 'relation': 'told', 'target': 'me'}, {'source': 'me', 'relation': 'wasn’t', 'target': 'me'}, {'source': 'HumemAI', 'relation': 'follows', 'target': 'Then'}, {'source': 'Then', 'relation': 'follows', 'target': 'next'}, {'source': 'Then', 'relation': 'follows', 'target': 'step'}, {'source': 'Then', 'relation': 'follows', 'target': 'the'}, {'source': 'Then', 'relation': 'follows', 'target': 'what'}]}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_pipeline(\"meta-llama/Llama-3.2-1B-Instruct\", \"cuda\", \"16bit\")\n",
    "\n",
    "history = {\"entities\": [], \"relations\": []}\n",
    "\n",
    "for chunk in tqdm(chunks):\n",
    "\n",
    "    outputs = pipeline(\n",
    "        generate_prompt(history, chunk),\n",
    "        max_new_tokens=1024,\n",
    "    )\n",
    "    text_content = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "\n",
    "    json_match = re.search(r\"```json\\n(.*?)\\n```\", text_content, re.DOTALL)\n",
    "\n",
    "    try:\n",
    "        json_text = json_match.group(1)  # Extract JSON content\n",
    "        dict_graph = json.loads(json_text)\n",
    "\n",
    "        # Write short term vertices\n",
    "        for entity in dict_graph[\"entities\"]:\n",
    "            vertex = humemai.write_short_term_vertex(\n",
    "                label=entity[\"label\"], properties=entity[\"properties\"]\n",
    "            )\n",
    "\n",
    "        # Write short term edges\n",
    "        for relation in dict_graph[\"relations\"]:\n",
    "            head_label = relation[\"source\"]\n",
    "            head_vertex = humemai.find_vertex_by_label(head_label)[0]\n",
    "            edge_label = relation[\"relation\"]\n",
    "            tail_label = relation[\"target\"]\n",
    "            tail_vertex = humemai.find_vertex_by_label(tail_label)[0]\n",
    "\n",
    "            edge = humemai.write_short_term_edge(\n",
    "                head_vertex=head_vertex,\n",
    "                edge_label=edge_label,\n",
    "                tail_vertex=tail_vertex,\n",
    "            )\n",
    "\n",
    "        # Get working memory vertices and edges\n",
    "        short_term_vertices, long_term_vertices, short_term_edges, long_term_edges = (\n",
    "            humemai.get_working_vertices_and_edges(\n",
    "                short_term_vertices=humemai.get_all_short_term_vertices(),\n",
    "                short_term_edges=humemai.get_all_short_term_edges(),\n",
    "                include_all_long_term=False,\n",
    "                hops=2,  # Include 2 hops of long-term memory\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Extract long-term entities and relations from the working memory to give it\n",
    "        # back to the LLM\n",
    "        entities = []\n",
    "        for vertex in long_term_vertices:\n",
    "            entities.append(\n",
    "                {\n",
    "                    \"label\": vertex.label,\n",
    "                    \"properties\": {\n",
    "                        key: val\n",
    "                        for key, val in humemai.get_vertex_properties(vertex).items()\n",
    "                        if key not in [\"num_recalled\", \"event_time\", \"known_since\"]\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "        relations = []\n",
    "        for edge in long_term_edges:\n",
    "            relations.append(\n",
    "                {\n",
    "                    \"source\": edge.outV.label,\n",
    "                    \"relation\": edge.label,\n",
    "                    \"target\": edge.inV.label,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # move all the short-term memories to the long-term memory. At the moment, they\n",
    "        # are all moved as \"episodic\". In the future, we may want to move some of them\n",
    "        # as \"semantic\" memories, or even forget some of them.\n",
    "        for vertex in short_term_vertices:\n",
    "            humemai.move_short_term_vertex(vertex, \"episodic\")\n",
    "\n",
    "        for edge in short_term_edges:\n",
    "            humemai.move_short_term_edge(edge, \"episodic\")\n",
    "\n",
    "        # remove all short term vertices and edges\n",
    "        humemai.remove_all_short_term()\n",
    "\n",
    "        history = {\"entities\": entities, \"relations\": relations}\n",
    "        print(\"history: \", history)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice --retraces--> Grace | Properties: {'num_recalled': 4, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --put_bag_down--> Bob | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 3}\n",
      "Alice --found--> InnovateAI | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 2}\n",
      "Alice --was_at--> Bob | Properties: {'num_recalled': 11, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --knows--> Bob | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 10}\n",
      "Alice --knows--> Grace | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 4}\n",
      "Alice --works_at--> Bob | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 10}\n",
      "Alice --took--> Bob | Properties: {'num_recalled': 12, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --may_have_taken--> Bob | Properties: {'num_recalled': 9, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --came_in--> Bob | Properties: {'num_recalled': 4, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --came_in--> HumemAI | Properties: {'num_recalled': 1, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --grabbed_coffee--> Bob | Properties: {'num_recalled': 4, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Alice --grabbed_coffee--> HumemAI | Properties: {'num_recalled': 1, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "you --told--> I | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 1}\n",
      "Bob --said--> I | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 2}\n",
      "Bob --told--> me | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 2}\n",
      "Bob --told--> I | Properties: {'num_recalled': 2, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Bob --knows--> Alice | Properties: {'num_recalled': 1, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Bob --knows--> InnovateAI | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 11}\n",
      "Bob --works_at--> InnovateAI | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 1}\n",
      "Bob --took--> Alice | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 9}\n",
      "Bob --may_have_taken--> Alice | Properties: {'num_recalled': 7, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Bob --may_have_taken--> HumemAI | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 1}\n",
      "HumemAI --follows--> Then | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 3}\n",
      "HumemAI --observes--> InnovateAI | Properties: {'num_recalled': 7, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Grace --inquired--> keys | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 5}\n",
      "Grace --may_have_inquired--> keys | Properties: {'num_recalled': 5, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Grace --asks--> Alice | Properties: {'num_recalled': 4, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Then --follows--> next | Properties: {'num_recalled': 2, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Then --follows--> step | Properties: {'num_recalled': 2, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "Then --follows--> the | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 2}\n",
      "Then --follows--> what | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 2}\n",
      "me --wasn’t--> me | Properties: {'num_recalled': 2, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "I --said--> Bob | Properties: {'num_recalled': 2, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "I --told--> you | Properties: {'num_recalled': 1, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n",
      "I --told--> me | Properties: {'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25'], 'num_recalled': 2}\n",
      "Charlie --asks--> What’s going on? | Properties: {'event_time': ['2024-11-20T15:00:25'], 'num_recalled': 1}\n",
      "InnovateAI --may_crisis_averated--> HumemAI | Properties: {'num_recalled': 1, 'event_time': ['2024-11-20T15:00:25', '2024-11-20T15:00:25']}\n"
     ]
    }
   ],
   "source": [
    "for edge in humemai.get_all_long_term_edges():\n",
    "    print(\n",
    "        f\"{edge.outV.label} --{edge.label}--> {edge.inV.label} | Properties: {humemai.get_edge_properties(edge)}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humemai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
