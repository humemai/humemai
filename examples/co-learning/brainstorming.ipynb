{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph learning\n",
    "\n",
    "<!-- ## JanusGraph-Visualizer queries\n",
    "\n",
    "- Visualize only the collaboration pattern nodes, situation nodes, and action nodes\n",
    "  - `g.V().not(hasLabel(containing(\"participant_\").or(eq(\"robot\"))))`\n",
    "- Visualize the situation vertices of interest\n",
    "  - `g.V().hasLabel(\"situation_1\", \"situation_2\")` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start HumemAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/humemai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "DEBUG:humemai.janusgraph.utils.docker:Starting Docker Compose with project name 'jce' using file '/home/tk/repos/humemai/humemai/janusgraph/docker-compose-cql-es.yml'...\n",
      "DEBUG:humemai.janusgraph.utils.docker:Waiting for 30 seconds to allow containers to warm up...\n",
      "INFO:humemai.janusgraph.utils.docker:Docker Compose started successfully.\n",
      "DEBUG:humemai.janusgraph.utils.docker:\n",
      "DEBUG:humemai.janusgraph.humemai:Attempting to establish a new connection to the Gremlin server.\n",
      "DEBUG:humemai.janusgraph.humemai:Gremlin server URL: ws://localhost:8182/gremlin\n",
      "INFO:gremlinpython:Creating DriverRemoteConnection with url 'ws://localhost:8182/gremlin'\n",
      "INFO:gremlinpython:Creating Client with url 'ws://localhost:8182/gremlin'\n",
      "INFO:gremlinpython:Creating GraphTraversalSource.\n",
      "INFO:gremlinpython:Creating GraphTraversalSource.\n",
      "INFO:humemai.janusgraph.humemai:Successfully connected to the Gremlin server.\n"
     ]
    }
   ],
   "source": [
    "from humemai.utils import disable_logger\n",
    "disable_logger()\n",
    "\n",
    "from gremlin_python.structure.graph import Graph, Vertex, Edge\n",
    "from gremlin_python.driver.driver_remote_connection import DriverRemoteConnection\n",
    "from gremlin_python.driver.serializer import GraphSONSerializersV3d0\n",
    "from gremlin_python.process.graph_traversal import __\n",
    "from gremlin_python.process.traversal import P, T, Direction\n",
    "\n",
    "import json\n",
    "from humemai.janusgraph import Humemai\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "humemai = Humemai()\n",
    "humemai.connect()\n",
    "\n",
    "\n",
    "# humemai.remove_all_data()\n",
    "# humemai.disconnect()\n",
    "# humemai.stop_docker_compose()\n",
    "# humemai.remove_docker_compose()\n",
    "\n",
    "from humemai.utils import disable_logger\n",
    "disable_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the co-learning data to HumemAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:02<00:00, 90.90it/s] \n"
     ]
    }
   ],
   "source": [
    "with open(\"./raw-data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "humemai.remove_all_data()\n",
    "\n",
    "\n",
    "for data_point in tqdm(data):\n",
    "    time_added = data_point[\"timestamp\"]\n",
    "\n",
    "    robot_vertex = humemai.write_long_term_vertex(\"robot\", {\"time_added\": time_added})\n",
    "    cp_properties = {\n",
    "        \"cp_num\": data_point[\"cp_num\"],\n",
    "        \"participant_num\": data_point[\"participant\"],\n",
    "        \"cp_name\": data_point[\"cp_name\"],\n",
    "        \"ticks_lasted\": data_point[\"ticks_lasted\"],\n",
    "        \"round_num\": data_point[\"round_num\"],\n",
    "        \"time_added\": data_point[\"timestamp\"],\n",
    "        \"time_elapsed\": data_point[\"time_elapsed\"],\n",
    "        \"remaining_rocks\": data_point[\"remaining_rocks\"],\n",
    "        \"victim_harm\": data_point[\"victim_harm\"],\n",
    "    }\n",
    "\n",
    "    cp_vertex = humemai.write_long_term_vertex(\"CP\", cp_properties)\n",
    "    humemai.write_long_term_edge(\n",
    "        robot_vertex, \"has_cp\", cp_vertex, {\"time_added\": time_added}\n",
    "    )\n",
    "\n",
    "    participant_vertex = humemai.write_long_term_vertex(\n",
    "        \"participant\",\n",
    "        {\"participant_number\": data_point[\"participant\"], \"time_added\": time_added},\n",
    "    )\n",
    "    humemai.write_long_term_edge(\n",
    "        participant_vertex, \"has_cp\", cp_vertex, {\"time_added\": time_added}\n",
    "    )\n",
    "\n",
    "    situation = [bar for foo in data_point[\"situation\"] for bar in foo]\n",
    "\n",
    "    if situation:\n",
    "        situation_properties = {s[\"type\"]: s[\"content\"] for s in situation}\n",
    "        situation_properties[\"time_added\"] = time_added\n",
    "        situation_vertex = humemai.write_long_term_vertex(\n",
    "            \"situation\", situation_properties\n",
    "        )\n",
    "        humemai.write_long_term_edge(\n",
    "            cp_vertex, \"has_situation\", situation_vertex, {\"time_added\": time_added}\n",
    "        )\n",
    "\n",
    "        for idx, list_ in enumerate(data_point[\"HumanAction\"]):\n",
    "\n",
    "            if list_:\n",
    "                properties = {\"time_added\": time_added}\n",
    "                for action in list_:\n",
    "                    properties[action[\"type\"]] = action[\"content\"]\n",
    "                properties[\"action_number\"] = idx\n",
    "\n",
    "                human_action_vertex = humemai.write_long_term_vertex(\n",
    "                    \"human_action\", properties\n",
    "                )\n",
    "                humemai.write_long_term_edge(\n",
    "                    situation_vertex,\n",
    "                    \"has_human_action_\" + str(idx),\n",
    "                    human_action_vertex,\n",
    "                    {\"time_added\": time_added},\n",
    "                )\n",
    "\n",
    "        for idx, list_ in enumerate(data_point[\"RobotAction\"]):\n",
    "\n",
    "            if list_:\n",
    "                properties = {\"time_added\": time_added}\n",
    "                for action in list_:\n",
    "                    properties[action[\"type\"]] = action[\"content\"]\n",
    "                properties[\"action_number\"] = idx\n",
    "\n",
    "                robot_action_vertex = humemai.write_long_term_vertex(\n",
    "                    \"robot_action\", properties\n",
    "                )\n",
    "                humemai.write_long_term_edge(\n",
    "                    situation_vertex,\n",
    "                    \"has_robot_action_\" + str(idx),\n",
    "                    robot_action_vertex,\n",
    "                    {\"time_added\": time_added},\n",
    "                )\n",
    "\n",
    "# # Merge the duplicate nodes\n",
    "# humemai.connect_duplicate_vertices(\"exact_label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "humemai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
